{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({SepalLength: (?,), SepalWidth: (?,), PetalLength: (?,), PetalWidth: (?,)}, (?,)), types: ({SepalLength: tf.float64, SepalWidth: tf.float64, PetalLength: tf.float64, PetalWidth: tf.float64}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tensorflow tutorial for predicting on the IRIS dataset\n",
    "Also contains general methods which will be useful for:\n",
    "\n",
    "* Downloading training and test sets given their URLs.\n",
    "* \"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Sentosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "\n",
    "\"\"\"The following two methods contain functionality for loading and reading\n",
    "data into the training and test sets.\"\"\"\n",
    "\n",
    "def download_if_not_in_cache(train_url, test_url, train_file_name, test_file_name):\n",
    "    \"\"\"Method to download a training and test set given their URLs.\n",
    "    * The method checks if the file already exists in the cache.\n",
    "    * If not it downloads and stores the file in the cache.\n",
    "    * Finally, it returns the path to the file which has been downloaded.\"\"\"\n",
    "    \n",
    "    train_file_path = tf.keras.utils.get_file(train_file_name, train_url)\n",
    "    test_file_path = tf.keras.utils.get_file(test_file_name, test_url)\n",
    "    \n",
    "    return train_file_path, test_file_path\n",
    "\n",
    "\n",
    "def load_data(train_url, test_url):\n",
    "    train_path, test_path = download_if_not_in_cache(train_url, test_url, train_url.split('/')[-1], test_url.split('/')[-1])\n",
    "\n",
    "    train = pd.read_csv(train_path, names = CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop('Species')\n",
    "    \n",
    "    test = pd.read_csv(test_path, names = CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop('Species')\n",
    "    \n",
    "    return ((train_x, train_y), (test_x, test_y))\n",
    "\n",
    "\n",
    "def train_input_function(train_x, train_y, batch_size):\n",
    "    \"\"\"Function to produce a dataset type object from the training data produced\n",
    "    by the load_data function above. The dataset type object produced by this method\n",
    "    can be passed to the 'train' function of the estimator (like DNNClassifier)\"\"\"\n",
    "    \n",
    "    # train_x is a DataFrame type object and we are converting it into a dictionary\n",
    "    # train_y is a Series type object <class 'pandas.core.series.Series'>\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(train_x), train_y))\n",
    "    \n",
    "    # Shuffling, Repeating and Batching the dataset\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def test_input_function(test_x, test_y, batch_size):\n",
    "    \"\"\"Similar function as above but for the test data set\"\"\"\n",
    "    features = dict(test_x)\n",
    "    \n",
    "    # This case may turn up when we are trying to make predictions\n",
    "    # on single points using a trained classifier\n",
    "    if test_y is None:\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, test_y)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    \n",
    "    #Batch size should not be none here.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "((train_x, train_y), (test_x, test_y)) = load_data(TRAIN_URL, TEST_URL)\n",
    "print (train_input_function(train_x, train_y, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\tmpsnu_m7t7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000007B50DD8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 117.246, step = 1\n",
      "INFO:tensorflow:global_step/sec: 729.885\n",
      "INFO:tensorflow:loss = 55.6792, step = 101 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.042\n",
      "INFO:tensorflow:loss = 18.5079, step = 201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 10.5022, step = 301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.335\n",
      "INFO:tensorflow:loss = 8.01538, step = 401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 7.22551, step = 501 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 7.31946, step = 601 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 11.5932, step = 701 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.816\n",
      "INFO:tensorflow:loss = 6.46825, step = 801 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.821\n",
      "INFO:tensorflow:loss = 5.8748, step = 901 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.335\n",
      "INFO:tensorflow:loss = 6.20283, step = 1001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.022\n",
      "INFO:tensorflow:loss = 3.35013, step = 1101 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.624\n",
      "INFO:tensorflow:loss = 5.93476, step = 1201 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.15\n",
      "INFO:tensorflow:loss = 4.31338, step = 1301 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.397\n",
      "INFO:tensorflow:loss = 5.42596, step = 1401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.608\n",
      "INFO:tensorflow:loss = 5.77271, step = 1501 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.286\n",
      "INFO:tensorflow:loss = 4.7469, step = 1601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.337\n",
      "INFO:tensorflow:loss = 6.41467, step = 1701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.944\n",
      "INFO:tensorflow:loss = 5.52228, step = 1801 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 1.61442, step = 1901 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.818\n",
      "INFO:tensorflow:loss = 8.16458, step = 2001 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.821\n",
      "INFO:tensorflow:loss = 5.85738, step = 2101 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.325\n",
      "INFO:tensorflow:loss = 6.54049, step = 2201 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.626\n",
      "INFO:tensorflow:loss = 8.82743, step = 2301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.399\n",
      "INFO:tensorflow:loss = 5.25878, step = 2401 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.188\n",
      "INFO:tensorflow:loss = 8.09409, step = 2501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.524\n",
      "INFO:tensorflow:loss = 2.74267, step = 2601 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.041\n",
      "INFO:tensorflow:loss = 5.6246, step = 2701 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.325\n",
      "INFO:tensorflow:loss = 5.58678, step = 2801 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 1.13116, step = 2901 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.526\n",
      "INFO:tensorflow:loss = 4.97713, step = 3001 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.344\n",
      "INFO:tensorflow:loss = 2.19566, step = 3101 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.143\n",
      "INFO:tensorflow:loss = 5.63817, step = 3201 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.605\n",
      "INFO:tensorflow:loss = 5.43321, step = 3301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 799.954\n",
      "INFO:tensorflow:loss = 2.30592, step = 3401 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.405\n",
      "INFO:tensorflow:loss = 6.23414, step = 3501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 934.526\n",
      "INFO:tensorflow:loss = 4.92022, step = 3601 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.653\n",
      "INFO:tensorflow:loss = 5.0425, step = 3701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.399\n",
      "INFO:tensorflow:loss = 1.99764, step = 3801 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.288\n",
      "INFO:tensorflow:loss = 4.2825, step = 3901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.596\n",
      "INFO:tensorflow:loss = 4.38595, step = 4001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.245\n",
      "INFO:tensorflow:loss = 4.74553, step = 4101 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.532\n",
      "INFO:tensorflow:loss = 4.66217, step = 4201 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.399\n",
      "INFO:tensorflow:loss = 4.50529, step = 4301 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.286\n",
      "INFO:tensorflow:loss = 3.65376, step = 4401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 763.315\n",
      "INFO:tensorflow:loss = 4.59456, step = 4501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.605\n",
      "INFO:tensorflow:loss = 4.24548, step = 4601 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 787.357\n",
      "INFO:tensorflow:loss = 2.84912, step = 4701 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 769.188\n",
      "INFO:tensorflow:loss = 4.92694, step = 4801 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.377\n",
      "INFO:tensorflow:loss = 4.00943, step = 4901 (0.110 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.8181.\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This part of the code deals with using a pre-existing Tensorflow estimator\n",
    "for the purpose of learning from the training set.\"\"\"\n",
    "\n",
    "\n",
    "def train_DNN_classifier(train_x, train_y, batch_size, num_steps):\n",
    "    \"\"\"Function to train a DNN classifier on the iris dataset\"\"\"\n",
    "    \n",
    "    # Step 1: Build the features\n",
    "    # At each step of the loop we are going to add a numeric column to\n",
    "    # the feature set.\n",
    "    feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "    \n",
    "    \n",
    "    # Step 2: Build the DNN model\n",
    "    # * We input the feature_column names we created above.\n",
    "    # * We input the structure of the hidden layers (two hidden layers each of 10 units)\n",
    "    # * We input the number of classes (because the default value = 2)\n",
    "    dnn_classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns = feature_columns,\n",
    "        hidden_units = [10,10],\n",
    "        n_classes = 3)\n",
    "    \n",
    "    \n",
    "    # Step 3: Train the DNN on the training set provided as parameters\n",
    "    # * Create a dataset out of the train_x and train_y objects\n",
    "    # * train the classifier on the dataset object thus produced\n",
    "    dnn_classifier.train(input_fn=lambda:train_input_function(train_x, train_y, batch_size), steps = num_steps)\n",
    "    \n",
    "    return dnn_classifier\n",
    "\n",
    "trained_classifier = train_DNN_classifier(train_x, train_y, 100, 5000)\n",
    "print (trained_classifier.model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-10-02:57:59\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\\model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-10-02:58:00\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.966667, average_loss = 0.06176, global_step = 5000, loss = 1.8528\n",
      "{'accuracy': 0.96666664, 'average_loss': 0.061760046, 'loss': 1.8528013, 'global_step': 5000}\n",
      "Accuracy:  96.6666638851 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This part of the code tests the trained DNN classifier on the test set.\"\"\"\n",
    "\n",
    "# Calculating overall test set error\n",
    "batch_size = 100\n",
    "eval_result = trained_classifier.evaluate(\n",
    "    input_fn = lambda:test_input_function(test_x, test_y, batch_size))\n",
    "\n",
    "print (eval_result)\n",
    "print ('Accuracy: ', eval_result['accuracy'] * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\USER\\AppData\\Local\\Temp\\tmpsnu_m7t7\\model.ckpt-5000\n",
      "\n",
      "Prediction is \"Sentosa\" (99.9%), expected \"Setosa\"\n",
      "\n",
      "Prediction is \"Versicolor\" (100.0%), expected \"Versicolor\"\n",
      "\n",
      "Prediction is \"Virginica\" (99.6%), expected \"Virginica\"\n"
     ]
    }
   ],
   "source": [
    "# Calculating predictions on some inputs\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predictions = trained_classifier.predict(\n",
    "    input_fn=lambda:test_input_function(predict_x,\n",
    "                                test_y=None,\n",
    "                                batch_size=batch_size))\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print(template.format(SPECIES[class_id],\n",
    "                          100 * probability, expec))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\My personal folder\\\\Computer Science Docs\\\\Postgrad(MSc)\\\\Project\\\\Tensorflow tutorial\\\\Iris\\\\model_checkpoints', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000000C56BBA8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\My personal folder\\Computer Science Docs\\Postgrad(MSc)\\Project\\Tensorflow tutorial\\Iris\\model_checkpoints\\model.ckpt.\n",
      "INFO:tensorflow:loss = 274.939, step = 1\n",
      "INFO:tensorflow:global_step/sec: 591.682\n",
      "INFO:tensorflow:loss = 20.948, step = 101 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 746.227\n",
      "INFO:tensorflow:loss = 11.0433, step = 201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.102\n",
      "INFO:tensorflow:loss = 9.30103, step = 301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.253\n",
      "INFO:tensorflow:loss = 5.82838, step = 401 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.405\n",
      "INFO:tensorflow:loss = 8.05608, step = 501 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.337\n",
      "INFO:tensorflow:loss = 6.99605, step = 601 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.624\n",
      "INFO:tensorflow:loss = 6.61436, step = 701 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.289\n",
      "INFO:tensorflow:loss = 5.78783, step = 801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.408\n",
      "INFO:tensorflow:loss = 5.97921, step = 901 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.872\n",
      "INFO:tensorflow:loss = 5.18681, step = 1001 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.342\n",
      "INFO:tensorflow:loss = 4.11724, step = 1101 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.485\n",
      "INFO:tensorflow:loss = 5.21695, step = 1201 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.653\n",
      "INFO:tensorflow:loss = 6.43798, step = 1301 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.286\n",
      "INFO:tensorflow:loss = 5.59379, step = 1401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.653\n",
      "INFO:tensorflow:loss = 3.0541, step = 1501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.039\n",
      "INFO:tensorflow:loss = 2.75159, step = 1601 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.818\n",
      "INFO:tensorflow:loss = 7.5241, step = 1701 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.04\n",
      "INFO:tensorflow:loss = 5.1739, step = 1801 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.379\n",
      "INFO:tensorflow:loss = 5.32339, step = 1901 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.288\n",
      "INFO:tensorflow:loss = 8.99213, step = 2001 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.045\n",
      "INFO:tensorflow:loss = 1.84964, step = 2101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.818\n",
      "INFO:tensorflow:loss = 4.2842, step = 2201 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.48\n",
      "INFO:tensorflow:loss = 4.00169, step = 2301 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.485\n",
      "INFO:tensorflow:loss = 5.3084, step = 2401 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.85\n",
      "INFO:tensorflow:loss = 4.8422, step = 2501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.377\n",
      "INFO:tensorflow:loss = 3.59034, step = 2601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.337\n",
      "INFO:tensorflow:loss = 4.83404, step = 2701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.335\n",
      "INFO:tensorflow:loss = 2.149, step = 2801 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.379\n",
      "INFO:tensorflow:loss = 4.60794, step = 2901 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.4\n",
      "INFO:tensorflow:loss = 4.87804, step = 3001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.284\n",
      "INFO:tensorflow:loss = 4.56061, step = 3101 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.143\n",
      "INFO:tensorflow:loss = 6.70953, step = 3201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.04\n",
      "INFO:tensorflow:loss = 2.22931, step = 3301 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1052.57\n",
      "INFO:tensorflow:loss = 5.56159, step = 3401 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.816\n",
      "INFO:tensorflow:loss = 2.18722, step = 3501 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.653\n",
      "INFO:tensorflow:loss = 4.25015, step = 3601 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.02\n",
      "INFO:tensorflow:loss = 1.99518, step = 3701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.039\n",
      "INFO:tensorflow:loss = 2.00196, step = 3801 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.485\n",
      "INFO:tensorflow:loss = 4.56443, step = 3901 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.818\n",
      "INFO:tensorflow:loss = 4.78652, step = 4001 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.377\n",
      "INFO:tensorflow:loss = 7.17531, step = 4101 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.02\n",
      "INFO:tensorflow:loss = 2.55175, step = 4201 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 925.872\n",
      "INFO:tensorflow:loss = 3.0508, step = 4301 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.042\n",
      "INFO:tensorflow:loss = 1.10363, step = 4401 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.329\n",
      "INFO:tensorflow:loss = 4.73732, step = 4501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.904\n",
      "INFO:tensorflow:loss = 3.81918, step = 4601 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.284\n",
      "INFO:tensorflow:loss = 2.85499, step = 4701 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 819.627\n",
      "INFO:tensorflow:loss = 3.69769, step = 4801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.325\n",
      "INFO:tensorflow:loss = 4.32279, step = 4901 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 7.22742, step = 5001 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.342\n",
      "INFO:tensorflow:loss = 4.65006, step = 5101 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.288\n",
      "INFO:tensorflow:loss = 3.53845, step = 5201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.515\n",
      "INFO:tensorflow:loss = 4.3898, step = 5301 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.485\n",
      "INFO:tensorflow:loss = 4.07918, step = 5401 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.344\n",
      "INFO:tensorflow:loss = 4.30413, step = 5501 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.483\n",
      "INFO:tensorflow:loss = 2.38285, step = 5601 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.02\n",
      "INFO:tensorflow:loss = 3.89541, step = 5701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.516\n",
      "INFO:tensorflow:loss = 1.47224, step = 5801 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 5.51194, step = 5901 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.333\n",
      "INFO:tensorflow:loss = 3.91173, step = 6001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.944\n",
      "INFO:tensorflow:loss = 4.61906, step = 6101 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.411\n",
      "INFO:tensorflow:loss = 4.2548, step = 6201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.018\n",
      "INFO:tensorflow:loss = 4.21661, step = 6301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.042\n",
      "INFO:tensorflow:loss = 6.06605, step = 6401 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 952.327\n",
      "INFO:tensorflow:loss = 3.94388, step = 6501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 961.485\n",
      "INFO:tensorflow:loss = 4.3598, step = 6601 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.409\n",
      "INFO:tensorflow:loss = 3.08074, step = 6701 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.397\n",
      "INFO:tensorflow:loss = 4.42508, step = 6801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.906\n",
      "INFO:tensorflow:loss = 4.11585, step = 6901 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 4.94833, step = 7001 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.335\n",
      "INFO:tensorflow:loss = 3.73877, step = 7101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.653\n",
      "INFO:tensorflow:loss = 1.53942, step = 7201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.399\n",
      "INFO:tensorflow:loss = 3.90876, step = 7301 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.806\n",
      "INFO:tensorflow:loss = 3.70124, step = 7401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 970.818\n",
      "INFO:tensorflow:loss = 3.05538, step = 7501 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.28789, step = 7601 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 943.344\n",
      "INFO:tensorflow:loss = 1.80067, step = 7701 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.944\n",
      "INFO:tensorflow:loss = 4.04139, step = 7801 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.87\n",
      "INFO:tensorflow:loss = 4.32164, step = 7901 (0.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.61\n",
      "INFO:tensorflow:loss = 3.33206, step = 8001 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.87\n",
      "INFO:tensorflow:loss = 3.6051, step = 8101 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 1041.61\n",
      "INFO:tensorflow:loss = 2.78623, step = 8201 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 1010.04\n",
      "INFO:tensorflow:loss = 3.01707, step = 8301 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.408\n",
      "INFO:tensorflow:loss = 3.72053, step = 8401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.908\n",
      "INFO:tensorflow:loss = 2.88377, step = 8501 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.039\n",
      "INFO:tensorflow:loss = 1.24305, step = 8601 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 909.037\n",
      "INFO:tensorflow:loss = 3.71817, step = 8701 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.87\n",
      "INFO:tensorflow:loss = 5.28537, step = 8801 (0.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.042\n",
      "INFO:tensorflow:loss = 1.79513, step = 8901 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1020.35\n",
      "INFO:tensorflow:loss = 4.05839, step = 9001 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.042\n",
      "INFO:tensorflow:loss = 3.27004, step = 9101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 990.045\n",
      "INFO:tensorflow:loss = 5.68746, step = 9201 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 999.941\n",
      "INFO:tensorflow:loss = 4.03608, step = 9301 (0.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.143\n",
      "INFO:tensorflow:loss = 6.03671, step = 9401 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.85\n",
      "INFO:tensorflow:loss = 2.52653, step = 9501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 869.516\n",
      "INFO:tensorflow:loss = 3.97932, step = 9601 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.904\n",
      "INFO:tensorflow:loss = 3.56504, step = 9701 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.906\n",
      "INFO:tensorflow:loss = 3.18798, step = 9801 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 892.806\n",
      "INFO:tensorflow:loss = 3.63771, step = 9901 (0.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\My personal folder\\Computer Science Docs\\Postgrad(MSc)\\Project\\Tensorflow tutorial\\Iris\\model_checkpoints\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.35695.\n"
     ]
    }
   ],
   "source": [
    "# This piece of code deals with a DNNClassifier with checkpoints\n",
    "def train_DNN_classifier_with_checkpoints(train_x, train_y, batch_size, num_steps):\n",
    "    \"\"\"Function to train a DNN classifier on the iris dataset with configured checkpoints\"\"\"\n",
    "    \n",
    "    # Step 1: Build the features\n",
    "    # At each step of the loop we are going to add a numeric column to\n",
    "    # the feature set.\n",
    "    feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        feature_columns.append(tf.feature_column.numeric_column(key = key))\n",
    "    \n",
    "    \n",
    "    # Step 2: Build the DNN model\n",
    "    # * We input the feature_column names we created above.\n",
    "    # * We input the structure of the hidden layers (two hidden layers each of 10 units)\n",
    "    # * We input the number of classes (because the default value = 2)\n",
    "    dnn_classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns = feature_columns,\n",
    "        hidden_units = [10,10],\n",
    "        model_dir = 'C:\\My personal folder\\Computer Science Docs\\Postgrad(MSc)\\Project\\Tensorflow tutorial\\Iris\\model_checkpoints',\n",
    "        n_classes = 3)\n",
    "    \n",
    "    \n",
    "    # Step 3: Train the DNN on the training set provided as parameters\n",
    "    # * Create a dataset out of the train_x and train_y objects\n",
    "    # * train the classifier on the dataset object thus produced\n",
    "    dnn_classifier.train(input_fn=lambda:train_input_function(train_x, train_y, batch_size), steps = num_steps)\n",
    "    \n",
    "    return dnn_classifier\n",
    "\n",
    "\n",
    "dnn_classifier = train_DNN_classifier_with_checkpoints(train_x, train_y, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
